# Assignment 5: RNN/LSTM and Transformers

This assignment is part of EECS 498-007 / 598-005: Deep Learning for Computer Vision (Winter 2022).

## Overview

In this assignment, you will implement recurrent neural networks (RNNs) and Transformers for sequence modeling tasks.

## Notebooks

### RNN/LSTM Image Captioning
- **File**: `rnn_lstm_captioning.ipynb`
- **Description**: Implement vanilla recurrent neural networks (RNN) and Long Short Term Memory (LSTM) RNNs. You will use these networks to train an image captioning model that generates natural language descriptions of images.

### Transformers ‚≠ê
- **File**: `Transformers.ipynb`
- **Description**: Implement the Transformer architecture with multi-head self-attention. You will learn about attention mechanisms and apply Transformers to sequence-to-sequence tasks.

## Python Files

- `rnn_lstm_captioning.py` - Implementation code for RNN/LSTM models
- `transformers.py` - Implementation code for Transformer architecture
- `a5_helper.py` - Helper functions for this assignment
- `two_digit_op.json` - Dataset for Transformer training
- `eecs598/` - Module with data loaders, solvers, and utilities

## Key Concepts

- Recurrent Neural Networks (RNNs)
- Long Short-Term Memory (LSTM)
- Attention mechanisms
- Self-attention and multi-head attention
- Transformer architecture
- Sequence-to-sequence models

## Getting Started

1. Open the notebook files in Jupyter or Google Colab
2. Follow the instructions in each notebook
3. Implement the required functions in the `.py` files
4. Train and evaluate your models

## Reference

This assignment is from the Winter 2022 offering of EECS 498-007 / 598-005 at the University of Michigan.
